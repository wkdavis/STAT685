---
title: "Introduction"
author: "William K Davis III"
date: "`r Sys.Date()`"
output:
  pdf_document:
    citation_package: natbib
bibliography: citations.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
  )
library(ggplot2)
options(scipen = 999)
```

# Evaluation

For the purposes of discussing model error rate, let $y_t$ be the
observed bike count in period $t$, $\hat{y}_t$ be the forecast bike count in
period $t$, and $\hat{e}_t=y_t-\hat{y}_t$ be the forecast error at time $t$.

## Error Rate

Given our stated use for these models is forecasting (prediction), when
discussing model evaluation we must first define the notion of forecast
(prediction) error rate.
There are a number of different metrics to use for forecast error, each
with their own benefits and drawbacks (@fcacc). 
We will use Mean Absolute Error (MAE) to select the best model from among the
list of candidate models. Unlike percent errors, which have the general form
$100\times\frac{\hat{e}}{y_t}$, MAE is defined when $y_t=0$. Further, squared
errors such as Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are
sensitive to outliers. Finally, MAE is on the same scale as the original dataset
(number of bikes per hour), which gives it nice properties of interpretability.
Therefore, MAE is the best error metric for selecting the best model and
estimating test error. For our purposes, we will use the following equation:

$$
\text{Mean Absolute Error}=\frac{1}{nm}\sum_{i=1}^n\sum_{j=1}^m|e_{ij}|
$$

Where $m=24$ is the number of periods for which bike count is forecast and
$n=50$ is the number of iterations in the cross-validation.

## Model Selection

Models will be selected and evaluated in the context of their use for
forecasting rather than
statistical inference. As such, we will use two rounds of time series
cross-validation (TSCV), one round for hyperparameter selection within each
modeling methodology and one round for selecting the best model from among the
different methodologies. TSCV consists of selecting a point or series of points
from the dataset as test sets, then selecting all prior points as the training
set (@fpp3). In the example in Figure F, the first iteration trains on the
first 5 observations (blue) and generates forecasts on the next 3 observations 
(green). In the second iteration the model trains on the first 5+3=8
observations and forecasts on the next 3 observations. This continues until
the final iteration, where the model trains on all but the last 3 observations
and then generates forecasts for the final 3 observations.
In this example 5 is the initialization value (the number of training
observations in the first iteration), 3 is the step size (the number of
observations that are added to the training set each iteration), and 3 is also
the horizon (the number of periods for which we generate a forecast).
Each of the forecasts
is then compared with actual (observed) values to evaluate the forecast.

```{r tscv-example, fig.height=3, fig.cap="Depiction of time series cross validation"}
per <- 1:20
i1 <- c(rep("T",5), rep("F", 3), rep(" ", 12))
i2 <- c(rep("T",8), rep("F", 3), rep(" ", 9))
i3 <- c(rep("T",11), rep("F", 3), rep(" ", 6))
i4 <- c(rep("T",14), rep("F", 3), rep(" ", 3))
i5 <- c(rep("T",17), rep("F", 3))

df = tibble::tibble(iteration = sort(rep(1:5, length(per))),
                    period = rep(per, 5),
                    type = c(i1, i2, i3, i4, i5))

ggplot(df, aes(x = period, y = -iteration, label = type, color = type)) +
  geom_segment(aes(xend = 22, yend = -iteration), 
               color = "black", 
               arrow = grid::arrow(type = "closed")) +
  geom_point(size = 5) +
  geom_text(color = "black") +
  scale_color_manual(values = c("T" = "#619CFF", "F" = "#00BA38", " " = "grey")) +
  scale_y_continuous(labels = abs, name = "Iteration", limits = c(-5.25, -.75)) +
  theme(legend.position = "none",
        panel.grid.minor = element_blank())
```

For this evaluation there will be two stages of TSCV. The first stage will
be to select optimal hyperparameters within each modeling method. The second
stage will be to select the best model from among the different modeling
methods. The first stage will have 50 iterations with a forecast horizon of 27 hours
and a step size of 24 hours. The second stage will have 10 iterations with the
same horizon and step size. The step size of 24 hours, aside from having
meaning as the length of a day, is meant to avoid possible serial correlation
in the errors that can occur with smaller step sizes, such as 1 hour (@prophet).

The last training period will be at 8:00pm with
forecast periods for 9:00pm to 11:00pm the following day. This serves to
simulate real-world usage, where the operator of a bike share program would
generate forecasts each day at 8:00pm, after peak demand, for the following day,
so that the overnight hours can be used to reallocating bikes based on the
forecast for the following day's demand. The first forecast period of the first 
iteration of the first cross validation stage will be on XX, and the last
forecast observation of the final (50th) iteration of the first stage will be
on YY. The first forecast observation of the first iteration of the second stage
will be on XX and the final forecast observation of the final (10th) iteration
of the second stage will be on YY. 

# Results

```{r results}
bikets_test_stretched <- bikets %>%
  mutate(BikeCount = na_if(BikeCount, 0),
         Workday = factor(gsub(" ", "", as.character(Workday)), levels = c("Workday", "NotWorkday")),
         BikeCountL1 = lag(BikeCount, 1),
         BikeCountL2 = lag(BikeCount, 2),
         BikeCountL3 = lag(BikeCount, 3),
         BikeCountL4 = lag(BikeCount, 4),
         BikeCountL5 = lag(BikeCount, 5),
         BikeCountL6 = lag(BikeCount, 6),
         BikeCountL7 = lag(BikeCount, 7),
         BikeCountL8 = lag(BikeCount, 8),
         BikeCountL9 = lag(BikeCount, 9),
         BikeCountL10 = lag(BikeCount, 10),
         BikeCountL11 = lag(BikeCount, 11),
         BikeCountL12 = lag(BikeCount, 12),
         BikeCountL24 = lag(BikeCount, 24)) %>%
  tidyr::fill(starts_with("BikeCountL"), .direction = "downup") %>%
  slice(n=-(1:24)) %>%
  slice_head(n = -24) %>%
  stretch_tsibble(.step = 24,
                  .init = nrow(bikets_cv),
                  .id = "fold")

new_data(bikets_cv_stretched, n = 24) %>%
            inner_join(bikets, by = "Hour") %>%
            mutate(
              BikeCount = na_if(BikeCount, 0),
              Workday = factor(
                gsub(" ", "", as.character(Workday)),
                levels = c("Workday", "NotWorkday")
              )
            )
# ARIMA

# Prophet
```

---
title: "Seoul Bike Data"
author:
- William K Davis III
- Pei-Yin Yang
- Max Kutschinski
date: "`r Sys.Date()`"
output:
  html_document:
    keep_md: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  cache = TRUE
  )
library(readr)
library(dplyr)
library(tsibble)
library(fabletools)
library(feasts)
library(ggplot2)
library(lubridate)
library(caret)
library(gridExtra)
library(corrplot)
library(tidyr)
library(GGally)
library(e1071)
```

http://archive.ics.uci.edu/ml/bikesets/Seoul+Bike+Sharing+Demand

# Read Data

```{r read}
bike <- readr::read_csv("SeoulBikeData.csv",
                        col_names = c("Date",
                                      "BikeCount",
                                      "Hour",
                                      "Temperature",
                                      "Humidity",
                                      "WindSpeed",
                                      "Visibility",
                                      "Dewpoint",
                                      "SolarRadiation",
                                      "Rainfall",
                                      "Snowfall",
                                      "Seasons",
                                      "Holiday",
                                      "FunctionalDay"),
                        skip = 1,
                        col_types = cols("Hour" = col_time(format = "%H"),
                                         Seasons = "f", 
                                         Holiday = "f",
                                         FunctionalDay = "f"))
```

## PCA

```{r PCA}
bike$Hour = as.factor(bike$Hour)

# Correct for skewness for PCA purposes
quantData = bike %>%
  select_if(is.numeric)
skewnessVec = quantData %>% sapply(., e1071::skewness)

skewnessCriterion = abs(skewnessVec)> 1

quantDataSkewedYJ = quantData %>%
  select_if(skewnessCriterion) %>%
  preProcess(method = 'YeoJohnson') %>%
  predict(quantData %>% select_if(skewnessCriterion)) # apply Yeo-Johnson transformation

quantDataNotSkewed = quantData %>%
  select_if(!skewnessCriterion)

quantDataCombined = cbind(quantDataSkewedYJ, quantDataNotSkewed)
#

# start PCA
bikeCountPCA = prcomp(quantDataCombined,scale=TRUE,center=TRUE)
XtransformPC = data.frame(bikeCountPCA$x)

screeplot(bikeCountPCA,type='lines') # First two PCs are informative

ggplot(data = XtransformPC, aes(x = PC1, y = PC2)) +
  geom_point() +
  coord_cartesian(xlim = c(min(XtransformPC$PC1,XtransformPC$PC2),max(XtransformPC$PC1,XtransformPC$PC2)), 
                  ylim = c(min(XtransformPC$PC1,XtransformPC$PC2),max(XtransformPC$PC1,XtransformPC$PC2)))+
  ggtitle("Summarizing via PCA")


# Closer inspection of most extreme observation (bottom right)
filter(bike,XtransformPC$PC1 == max(XtransformPC$PC1)) # doesn't look very unusual besides high Humidity


```


## Feature Engineering

```{r FE}

# Extract features from date
bike$Day = factor(format(bikets$Hour, "%d"))
bike$Month = factor(months(bikets$Hour, abbreviate= T)) 
bike$WeekDay = factor(wday(bikets$Hour, label =F, week_start = 1), ordered = F)
bike$Hour = factor(format(bikets$Hour, "%H"))

# drop last 3 rows since we're not using those. (Similar to Fold 51 in create_cv_folds.R)
# bike = slice(bike, 1:(n() - 3))

# convert categorical features to numeric encoding
factors = c("Seasons", "Holiday", "FunctionalDay", "Day", "Month", "WeekDay", "Hour")
bike[,factors] = sapply(bike[,factors], unclass)
bike[,factors] <- lapply(bike[,factors], as.factor)

# create dummy vars
XQual = bike %>% 
  select(-c(Date,BikeCount)) %>%
  select_if(is.factor)
dummyModel = dummyVars(~., data = XQual, fullRank=TRUE)
XQualDummy = predict(dummyModel, XQual)
XQuan = bike %>% select(-c(names(XQual),Date,BikeCount))
XFull = cbind(XQualDummy, XQuan)
```

## Imputation

```{r Imp}
# Imputing values for Humidity using KNN
# BikeCount NA values should be predicted rather than imputed since it is the supervisor and not a feature
###

XFull = XFull %>%
  mutate(Humidity = ifelse(Humidity == 0, NA, Humidity))%>% # convert 0 to NA before imputing
  select(Humidity) %>%
  preProcess(method='knnImpute') %>% # Note that this automatically centers and scales Humidity
  predict(newdata = XFull)
```

# Modeling

## Machine Learning

### XGBoost

```{r XGBoost}
doParallel::registerDoParallel(cores = 6)
myTuneGrid = expand.grid('nrounds'=c(200,500), #grid still needs tuning
                       'max_depth'= 4,
                       'eta' = 0.01,
                       'gamma' = c(0,0.1),
                       'colsample_bytree' = 0.8,
                       'min_child_weight' = 1,
                       'subsample' = 0.8) 
cv_n <- nrow(bike)-(24*50)
bikecv <- slice_head(bike, n=cv_n)
myTrainControl = trainControl(method="timeslice", 
                              initialWindow = nrow(bikecv)*.8,
                              horizon = 24, 
                              skip = 23,
                              fixedWindow = FALSE,
                              verboseIter = TRUE)

boostOut = train(XFull[1:cv_n, ] , bike$BikeCount[1:cv_n],
                 metric = "MAE",
                 method = "xgbTree",
                 tuneGrid = myTuneGrid,
                 trControl = myTrainControl)

boostOut$bestTune
boostOut$results

myTestControl = trainControl(method="timeslice", 
                              initialWindow = nrow(bikecv),
                              horizon = 24, 
                              skip = 23,
                              fixedWindow = FALSE,
                              verboseIter = TRUE)

testOut = train(XFull, bike$BikeCount,
                 metric = "MAE",
                 method = "xgbTree",
                 tuneGrid = boostOut$bestTune,
                 trControl = myTestControl)

testOut$results

```


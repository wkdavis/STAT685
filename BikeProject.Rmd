---
title: "Seoul Bike Data"
author:
- William K Davis III
- Pei-Yin Yang
- Max Kutschinski
date: "`r Sys.Date()`"
output:
  html_document:
    keep_md: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  cache = TRUE
  )
library(readr)
library(dplyr)
library(tsibble)
library(fabletools)
library(feasts)
library(ggplot2)
library(lubridate)
library(caret)
library(gridExtra)
library(corrplot)
library(tidyr)
library(GGally)
library(e1071)
```

http://archive.ics.uci.edu/ml/bikesets/Seoul+Bike+Sharing+Demand

# Read Data

```{r read}
set.seed(123)
bike <- readr::read_csv("SeoulBikeData.csv",
                        col_names = c("Date",
                                      "BikeCount",
                                      "Hour",
                                      "Temperature",
                                      "Humidity",
                                      "WindSpeed",
                                      "Visibility",
                                      "Dewpoint",
                                      "SolarRadiation",
                                      "Rainfall",
                                      "Snowfall",
                                      "Seasons",
                                      "Holiday",
                                      "FunctionalDay"),
                        skip = 1,
                        col_types = cols("Hour" = col_time(format = "%H"),
                                         Seasons = "f", 
                                         Holiday = "f",
                                         FunctionalDay = "f"))
```

## Data Cleaning

```{r clean-ts}
bikets <- bike %>%
  mutate(
    Hour = parse_date_time(
      paste(Date, Hour),
      orders = c("dmy HMS", "dmY HMS"),
      tz = "Asia/Seoul"
    ),
    .before = everything(),
    Date = NULL
  ) %>%
  as_tsibble(index = Hour)

bikets_tall <- bikets %>%
  select(Hour, where(is.numeric)) %>%
  pivot_longer(cols = -Hour,
               names_to = "Measure",
               values_to = "Value")
  
bikets %>% count_gaps()
```

# EDA

## Data Summary

```{r data-desc, echo =T}
colnames(bikets)
anyNA(bikets)
dim(bikets)
str(bikets)
summary(bikets) # Investigate BikeCount = 0 and Humidity = 0
sum(bike$BikeCount==0) # 295 NAs
```

Notice there are no missing values. However there are some observations with BikeCount = 0, which correspond to non-functional days. Can these be treated as missing values and be imputed?
- Humidity has a minimum value of 0. Is this realistic? (see feature plot for further investigation)

```{r functional-day-eda}
bike %>% group_by(FunctionalDay) %>% summarise(bc = sum(BikeCount))
bike %>% filter(FunctionalDay == "Yes", BikeCount == 0)
```

It looks like FunctionalDay=No only has BikeCount = 0, and there are no
FunctionalDay=Yes with BikeCount > 0. Based on this I think it makes sense to
treat those days as missing data (i.e. set `BikeCount=NA`). The imputation
should probably happen during the modeling phase, as different modeling methods
might handle missing data differently.

## Feature Plots

```{r feature-plots, echo=F}
theme_set(theme_bw())

# modeling continuous features

X = select_if(bike, is.numeric)
Y = select(bike, BikeCount) %>% unlist()
featurePlot(X,Y)
```

Something seems to be going on with humidity = 0 values.

\newpage

## Scatter plots for numerical variables and box plot for categorical variables

```{r EDA}
library(gridExtra)

level_order <- c('Spring', 'Summer', 'Autumn', 'Winter')

season <- bike %>% 
  ggplot(aes(factor(Seasons, levels = level_order), BikeCount, fill = Holiday)) +
  geom_boxplot() + 
  labs(x = "",y = 'Bike Rental Count', 
       title = 'Bike Rental by Seasons') +
  theme_bw()

# rentals by hour, split by holiday (or not)
hour <- bike %>% group_by(Hour, Holiday) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(x = Hour, y = AvgBikeCount, col = Holiday)) +
  labs(x = "",y = 'Average Bike Rental', 
       title = 'Average Bike Rental by Hours') +
  geom_line() + theme_bw()

bike %>%
  ggplot(aes(Hour, BikeCount, col = factor(Hour))) +
  geom_boxplot() + 
  labs(x = "",y = 'Bike Rental Count', 
       title = 'Bike Rental by Seasons') 


bike %>% group_by(FunctionalDay) %>%
  summarise(SumBikeCount = sum(BikeCount)) 
unique(bike$FunctionalDay)
#bike count of non-Functional day = 0. Agreed with treating them as NA.

rainfall <- bike %>% group_by(Rainfall) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(Rainfall, AvgBikeCount)) +
  geom_point() + 
  labs(x = "Rainfall (mm)", y = 'Average Bike Rental', 
       title = 'Average Bike Rental against Rainfall') + 
  theme_bw()

snowfall <- bike %>% group_by(Snowfall) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(Snowfall, AvgBikeCount)) +
  geom_point() + 
  labs(x = "Snowfall (cm)", y = 'Average Bike Rental',
       title = 'Average Bike Rental against Snowfall') + theme_bw()

temp <- bike %>% group_by(Temperature) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(Temperature, AvgBikeCount)) +
  geom_point() + 
  labs(x = "Temperature (celcius)", y = 'Average Bike Rental',
       title = 'Average Bike Rental against Temperature') + theme_bw()

humidity <- bike %>% group_by(Humidity) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(Humidity, AvgBikeCount)) +
  geom_point() + 
  labs(x = "Humidity (%)", y = 'Average Bike Rental',
       title = 'Average Bike Rental against Humidity') + theme_bw()

wp <- bike %>% group_by(WindSpeed) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(WindSpeed, AvgBikeCount)) +
  geom_point() + 
  labs(x = "WindSpeed (m/s)", y = 'Average Bike Rental',
       title = 'Average Bike Rental against Wind Speed') + theme_bw()

vis <- bike %>% group_by(Visibility) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(Visibility, AvgBikeCount)) +
  geom_point() + 
  labs(x = "Visibility (10m)", y = 'Average Bike Count',
       title = 'Average Bike Rental against Visibility') + theme_bw()

dew <- bike %>% group_by(Dewpoint) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(Dewpoint, AvgBikeCount)) +
  geom_point() + 
  labs(x = "Dewpoint (Celsius)", y = 'Average Bike Count',
       title = 'Average Bike Rental against Dewpoint') + theme_bw()

solar <- bike %>% group_by(SolarRadiation) %>%
  summarise(AvgBikeCount = mean(BikeCount)) %>%
  ggplot(aes(SolarRadiation, AvgBikeCount)) +
  geom_point(stat='identity') + 
  labs(x = "SolarRadiation (MJ/m2)", y = 'Average Bike Count',
       title = 'Average Bike Rental against Solar Radiation') + theme_bw()

grid.arrange(season, hour, nrow=2)
grid.arrange(temp, dew, rainfall, snowfall, humidity, solar, wp, vis, nrow=4, ncol = 2)
```

## Correlation Plot

```{r corr-plots, echo=F}
ggscatmat(bike, 
          columns = c("BikeCount", "Temperature", "Humidity", "WindSpeed", 
                      "Visibility", "Dewpoint", "SolarRadiation", "Rainfall", 
                      "Snowfall"), 
          alpha = .2)
corrplot(cor(X), order = "hclust", tl.cex = 1.4)
```

Dewpoint and Temperature potentially problematic

\newpage

## Bike Demand by Hour of Day

```{r demand-by-day, echo=F, message=F,warning=F}
bike$Hour = hour(bike$Hour)

p1 = bike%>%group_by(Hour)%>%summarise(BikeCountMean = mean(BikeCount))%>%data.frame()%>%
  ggplot(mapping = aes(x=Hour ,y = BikeCountMean)) +
  geom_line()+
  geom_hline(aes(yintercept = mean(bike$BikeCount)), color = "red") +
  labs(y = "Average Bike Count",
       title = "Average Bike Demand by Hour of Day")


p2 = bike%>%group_by(Seasons,Hour)%>%summarise(BikeCountMean = mean(BikeCount))%>%data.frame()%>%
  ggplot(mapping = aes(x=Hour,y = BikeCountMean,color = Seasons, fill= Seasons)) +
  geom_line()+
  labs(y = "Average Bike Count",
       title = "Seasonal Average Bike Count by Hour of Day")

grid.arrange(p1,p2,ncol=1)

```


## Time Series Plots

```{r ts-plots}
autoplot(bikets, .vars = BikeCount) + labs(title = "Bike Count by Hour")
hist(bikets$BikeCount)
bikets_tall %>%
  ggplot(aes(x = Hour, y = Value, color = Measure)) +
  geom_line() +
  facet_grid(rows = vars(Measure), scales = "free_y")
ACF(bikets_tall, Value) %>% autoplot()
features(bikets_tall, Value, 
         c(unitroot_kpss, unitroot_ndiffs, unitroot_nsdiffs, ljung_box))
```

KPSS and Ljung-Box Test both indicate (auto)correlation within each
variable.

## PCA

```{r PCA}
bike$Hour = as.factor(bike$Hour)

# Correct for skewness for PCA purposes
quantData = bike %>%
  select_if(is.numeric)
skewnessVec = quantData %>% sapply(., e1071::skewness)

skewnessCriterion = abs(skewnessVec)> 1

quantDataSkewedYJ = quantData %>%
  select_if(skewnessCriterion) %>%
  preProcess(method = 'YeoJohnson') %>%
  predict(quantData %>% select_if(skewnessCriterion)) # apply Yeo-Johnson transformation

quantDataNotSkewed = quantData %>%
  select_if(!skewnessCriterion)

quantDataCombined = cbind(quantDataSkewedYJ, quantDataNotSkewed)
#

# start PCA
bikeCountPCA = prcomp(quantDataCombined,scale=TRUE,center=TRUE)
XtransformPC = data.frame(bikeCountPCA$x)

screeplot(bikeCountPCA,type='lines') # First two PCs are informative

ggplot(data = XtransformPC, aes(x = PC1, y = PC2)) +
  geom_point() +
  coord_cartesian(xlim = c(min(XtransformPC$PC1,XtransformPC$PC2),max(XtransformPC$PC1,XtransformPC$PC2)), 
                  ylim = c(min(XtransformPC$PC1,XtransformPC$PC2),max(XtransformPC$PC1,XtransformPC$PC2)))+
  ggtitle("Summarizing via PCA")


# Closer inspection of most extreme observation (bottom right)
filter(bike,XtransformPC$PC1 == max(XtransformPC$PC1)) # doesn't look very unusual besides high Humidity


```


## Feature Engineering

```{r FE}

# Extract features from date
bike$Day = factor(format(bikets$Hour, "%d"))
bike$Month = factor(months(bikets$Hour, abbreviate= T)) 
bike$WeekDay = factor(wday(bikets$Hour, label =F, week_start = 1), ordered = F)

# drop last 3 rows since we're not using those. (Similar to Fold 51 in create_cv_folds.R)
bike = slice(bike, 1:(n() - 3))

# convert categorical features to numeric encoding
factors = c("Seasons", "Holiday", "FunctionalDay", "Day", "Month", "WeekDay")
bike[,factors] = sapply(bike[,factors], unclass)
bike[,factors] <- lapply(bike[,factors], as.factor)

# create dummy vars
XQual = bike %>% 
  select(-c(Date,BikeCount)) %>%
  select_if(is.factor)
dummyModel = dummyVars(~., data = XQual, fullRank=TRUE)
XQualDummy = predict(dummyModel, XQual)
XQuan = bike %>% select(-c(names(XQual),Date,BikeCount))
XFull = cbind(XQualDummy, XQuan)
```

## Imputation

```{r Imp}
# Imputing values for Humidity using KNN
# BikeCount NA values should be predicted rather than imputed since it is the supervisor and not a feature
###

XFull = XFull %>%
  mutate(Humidity = ifelse(Humidity == 0, NA, Humidity))%>% # convert 0 to NA before imputing
  select(Humidity) %>%
  preProcess(method='knnImpute') %>% # Note that this automatically centers and scales Humidity
  predict(newdata = XFull)
```

# Modeling

## Time Series

* Prophet
* fasster


```{r model-prophet, eval=FALSE}
library(fable.prophet)

holidays <- bikets %>% 
  filter(Holiday == "Holiday") %>%
  mutate(ds = as.Date(Hour)) %>%
  distinct(ds) %>% 
  mutate(holiday = "holiday")

fit <- bikets %>%
  model(
    mdl = prophet(BikeCount ~ season(period = "day", type = "multiplicative") + season(period = "week", type = "multiplicative") + holiday(holidays = holidays)),
  )
components(fit) %>% autoplot()

```

## Machine Learning

### XGBoost

```{r XGBoost}
myTuneGrid = data.frame('nrounds'=c(200,500), #grid still needs tuning
                       'max_depth'= 4,
                       'eta' = 0.01,
                       'gamma' = c(0,0.1),
                       'colsample_bytree' = 0.8,
                       'min_child_weight' = 1,
                       'subsample' = 0.8) 

myTrainControl = trainControl(method="timeslice", 
                              initialWindow = nrow(bike)-(50*24),
                              horizon = 24, 
                              skip = 23,
                              fixedWindow = TRUE)


boostOut = train(XFull , bike$BikeCount,
                 method = "xgbTree",
                 tuneGrid = myTuneGrid,
                 trControl = myTrainControl)

boostOut$bestTune
boostOut$results


#sanity check
#timeSlices <- createTimeSlices(1:nrow(bike), 
#                   initialWindow = nrow(bike)-(50*24), horizon = 24, fixedWindow = T, skip = 23)

#tail(bike[timeSlices$train$Training7581,],1)
#bike[timeSlices$test$Testing7557,]

```



* LSTM
* RNN

